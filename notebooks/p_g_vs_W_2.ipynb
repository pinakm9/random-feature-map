{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be0232f4-b2a1-4b00-b4df-1ae3397e94a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from scipy.integrate import odeint\n",
    "import os, sys, warnings\n",
    "from pathlib import Path\n",
    "from os.path import dirname, realpath\n",
    "script_dir = Path(dirname(realpath('.')))\n",
    "module_dir = str(script_dir)\n",
    "sys.path.insert(0, module_dir + '/modules')\n",
    "import utility as ut\n",
    "import sample as sm\n",
    "import surrogate as sr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import wasserstein_torch as w2\n",
    "from joblib import Parallel, delayed\n",
    "import csv\n",
    "\n",
    "repo = '..'\n",
    "\n",
    "L63_data_folder = '{}/data/L63-trajectories'.format(repo)\n",
    "train = np.load('{}/train.npy'.format(L63_data_folder))\n",
    "L0, L1, D, D_r = 0.4, 3.5, 3, 300\n",
    "sampler = sm.MatrixSampler(L0, L1, train.T)\n",
    "training_points = 20000\n",
    "N_max = train.shape[1]\n",
    "beta = 4e-5\n",
    "n_w2 = 10000\n",
    "n_reps = 5\n",
    "n_attr = 100000\n",
    "attractor = torch.tensor(train[:, np.random.choice(N_max, n_w2, replace=False)].T, dtype=torch.float32)\n",
    "def compute_sinkhorn(a, b):\n",
    "    \"\"\"Helper function to compute sinkhorn divergence on the given tensors.\"\"\"\n",
    "    return float(w2.sinkhorn_div(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f90706-bc19-41e8-9938-2e8466941d08",
   "metadata": {},
   "source": [
    "**Given a partition produce a model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93da9a2d-49cd-4e31-8c31-fc74445bead0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 0.0% at rep 0\n",
      "Time taken by sample is 0.0233 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pman0581/Documents/GitHub/random-feature-map/modules/surrogate.py:79: RuntimeWarning: overflow encountered in matmul\n",
      "  R = np.tanh(self.W_in @ obs[:, :-1] + self.b_in[:, np.newaxis])#np.hstack([self.phi(uo).reshape(-1, 1) for uo in obs.T])\n",
      "/Users/pman0581/Documents/GitHub/random-feature-map/modules/surrogate.py:68: RuntimeWarning: overflow encountered in matmul\n",
      "  return np.tanh(self.W_in @ uo + self.b_in)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by get_model is 0.7759 seconds\n",
      "Time taken by sample is 0.0089 seconds\n",
      "Time taken by get_model is 0.5862 seconds\n",
      "Time taken by get_distance is 243.7321 seconds\n",
      "Working on 0.0% at rep 1\n",
      "Time taken by sample is 0.0091 seconds\n",
      "Time taken by get_model is 0.5607 seconds\n",
      "Time taken by sample is 0.0092 seconds\n",
      "Time taken by get_model is 0.5567 seconds\n"
     ]
    }
   ],
   "source": [
    "def get_row_partitions_50_50(percent):\n",
    "    good = int(percent * D_r / 100.)\n",
    "    linear = int((100. - percent) * D_r / 200.)\n",
    "    extreme = D_r - good - linear\n",
    "    return [good, linear, extreme]\n",
    "\n",
    "@ut.timer\n",
    "def get_model(percent):\n",
    "    partition = get_row_partitions_50_50(percent)\n",
    "    W_ins, b_ins = sampler.sample(partition, 1); \n",
    "    W_in, b_in = W_ins[0], b_ins[0]\n",
    "    model = sr.SurrogateModel_LR(D, D_r, W_in, b_in)\n",
    "    random_index = np.random.randint(N_max-training_points-1)\n",
    "    model.compute_W(train[:, random_index:random_index+training_points], beta=beta);\n",
    "    x0 = train[:, random_index]\n",
    "    attractor = model.multistep_forecast(x0, n_attr)\n",
    "    random_indices = np.random.choice(n_attr, n_w2, replace=False)\n",
    "    return attractor[:, random_indices].T\n",
    "\n",
    "@ut.timer\n",
    "def get_distance(percent):\n",
    "    pseudo_attractor = torch.tensor(get_model(10), dtype=torch.float32)\n",
    "    # Build the pseudo attractor.\n",
    "    pseudo_attractor = torch.tensor(get_model(10), dtype=torch.float32)\n",
    "    \n",
    "    # Create the tasks for the four different comparisons.\n",
    "    tasks = [\n",
    "        (attractor, pseudo_attractor),\n",
    "        (attractor[:, 0].reshape(-1, 1), pseudo_attractor[:, 0].reshape(-1, 1)),\n",
    "        (attractor[:, 1].reshape(-1, 1), pseudo_attractor[:, 1].reshape(-1, 1)),\n",
    "        (attractor[:, 2].reshape(-1, 1), pseudo_attractor[:, 2].reshape(-1, 1))\n",
    "    ]\n",
    "    \n",
    "    # Run all tasks in parallel.\n",
    "    results = Parallel(n_jobs=-1)(\n",
    "        delayed(compute_sinkhorn)(a, b) for a, b in tasks\n",
    "    )\n",
    "    \n",
    "    # Unpack the results.\n",
    "    distance_full, distance_x, distance_y, distance_z = results\n",
    "    return distance_full, distance_x, distance_y, distance_z \n",
    "\n",
    "csv_file = '../data/w2_data/w2.csv'\n",
    "with open(csv_file, mode='w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # Write a header row.\n",
    "    writer.writerow(['p_g', 'w2', 'w2_x', 'w2_y', 'w2_z'])\n",
    "    for percent in np.linspace(0, 100, 21, endpoint=True):\n",
    "        for rep in range(n_reps):\n",
    "            print(\"Working on {}% at rep {}\".format(percent, rep))\n",
    "            distance_full, distance_x, distance_y, distance_z = get_distance(percent)\n",
    "             # Write the current percent and computed distances to the CSV file.\n",
    "            writer.writerow([percent/100., distance_full, distance_x, distance_y, distance_z])\n",
    "            # Flush the buffer so that the file gets updated after each iteration.\n",
    "            f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90150031-4304-42da-9764-1ef6f08c8b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   5.,  10.,  15.,  20.,  25.,  30.,  35.,  40.,  45.,  50.,\n",
       "        55.,  60.,  65.,  70.,  75.,  80.,  85.,  90.,  95., 100.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ab88531-4f64-40a0-833b-a204eecbe855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.44238215684890747, tensor(0.0353), tensor(0.0363), tensor(0.0322))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_full, distance_x, distance_y, distance_z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "967741d6-a3b7-4b12-909b-6f6c8e76a569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.5190919637680054,\n",
       " 0.2334129959344864,\n",
       " 0.25071948766708374,\n",
       " 0.23227617144584656)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_full, distance_x, distance_y, distance_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70443be5-9942-432e-bc01-e5cf6f201125",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
